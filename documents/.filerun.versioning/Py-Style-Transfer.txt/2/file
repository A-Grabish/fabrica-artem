Py Style Transfer uses a abbriviated version of a VGG19 pretrained framework (with the addition of Markov Random Field at higher levels), pytorch, and Neural Doodle's semantic maps to transfer the style of one image onto the content of another.  The content loss function uses a lower layer than other methods to preserve more content detail.  Style loss is caculated using only three of the middle layers, versus the four or five layer calculation which use low, middle and high layers favored by other programers.

The synthesized images are visually coherent, and preserve the content of the orginal well while implementing elements of the style image to suppliment the shading.  The resulting images are small, and the user has little control over the values of variables used.
