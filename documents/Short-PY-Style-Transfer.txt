Py Style Transfer uses a abbriviated version of a VGG19 pretrained framework (with the addition of Markov Random Field at higher levels), pytorch, and Neural Doodle's semantic maps to transfer the style of one image onto the content of another.  The synthesized images are visually coherent, and preserve the content of the orginal well while implementing elements of the style image to suppliment the shading.  The resulting images are small, and the user has little control over the values of variables used.